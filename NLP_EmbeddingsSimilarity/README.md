# ðŸ“Š Embeddings & Similarity Flashcards

## ðŸ“š Overview
Vector representations and text similarity. **4 essential cards** covering how text becomes numbers and how we measure relationships.

## ðŸ“Š Deck Contents
- **Word embeddings** concept and training
- **Word2Vec vs contextual** embeddings comparison
- **Cosine similarity** formula and intuition
- **Cosine vs Euclidean** similarity trade-offs

## ðŸš€ Import to Anki
1. **Copy this entire folder** to your computer
2. **Open Anki** â†’ `File` â†’ `CrowdAnki: Import from disk`
3. **Select this folder** (`NLP_EmbeddingsSimilarity`)
4. **Import** - deck will appear as "Embeddings & Similarity"

## ðŸ“± Study Settings
- **New cards**: 10-15 per day
- **Review time**: ~18 seconds per card
- **Total study**: 6-10 minutes daily

## ðŸŽ¯ Learning Focus
Understand how text becomes vectors and how we measure semantic similarity. Foundation for search, recommendation, and most NLP applications.
