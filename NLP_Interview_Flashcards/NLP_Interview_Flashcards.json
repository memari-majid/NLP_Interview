{
  "__type__": "Deck",
  "children": [],
  "crowdanki_uuid": "nlp-interview-deck-rules-optimized-2024",
  "deck_config_uuid": "nlp-deck-config-rules-optimized",
  "deck_configurations": [
    {
      "__type__": "DeckConfig",
      "autoplay": true,
      "crowdanki_uuid": "nlp-deck-config-rules-optimized",
      "dyn": false,
      "name": "NLP Interview Prep (Rules Optimized)",
      "new": {
        "delays": [
          1,
          10
        ],
        "initialFactor": 2500,
        "ints": [
          1,
          4,
          7
        ],
        "order": 1,
        "perDay": 25
      },
      "rev": {
        "ease4": 1.3,
        "hardFactor": 1.2,
        "ivlFct": 1.0,
        "maxIvl": 36500,
        "perDay": 100
      }
    }
  ],
  "desc": "Rules-optimized NLP interview cards following research-backed design principles for maximum memorization effectiveness and rapid recall under interview pressure.",
  "dyn": 0,
  "extendNew": 10,
  "extendRev": 50,
  "media_files": [],
  "name": "NLP Interview Prep (Rules Optimized)",
  "note_models": [
    {
      "__type__": "NoteModel",
      "crowdanki_uuid": "nlp-model-rules-optimized",
      "css": ".card {\n    font-family: 'SF Pro Display', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n    font-size: 18px;\n    line-height: 1.6;\n    color: #2c3e50;\n    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n    text-align: left;\n    padding: 20px;\n    border-radius: 12px;\n    box-shadow: 0 4px 20px rgba(0,0,0,0.1);\n    max-width: 100%;\n    margin: 0 auto;\n}\n\n/* Mobile-first responsive design */\n@media (max-width: 480px) {\n    .card {\n        font-size: 16px;\n        padding: 15px;\n        margin: 10px;\n    }\n}\n\n/* Typography hierarchy */\nh1, h2, h3 {\n    color: #34495e;\n    margin-top: 0;\n    font-weight: 600;\n}\n\nh2 {\n    font-size: 20px;\n    color: #3498db;\n    border-bottom: 2px solid #3498db;\n    padding-bottom: 5px;\n}\n\nh3 {\n    font-size: 18px;\n    color: #e74c3c;\n}\n\n/* Color coding system */\n.concept { color: #3498db; font-weight: 600; }\n.implementation { color: #27ae60; }\n.formula { color: #f39c12; font-weight: 700; }\n.edge-case { color: #e74c3c; }\n.interview-tip { color: #9b59b6; font-style: italic; }\n\n/* Code styling for mobile */\npre, code {\n    font-family: 'SF Mono', 'Monaco', 'Consolas', monospace;\n    font-size: 14px;\n    background: #2c3e50;\n    color: #ecf0f1;\n    padding: 12px;\n    border-radius: 8px;\n    overflow-x: auto;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    line-height: 1.4;\n    margin: 10px 0;\n}\n\n@media (max-width: 480px) {\n    pre, code {\n        font-size: 13px;\n        padding: 8px;\n    }\n}\n\n/* Inline code */\ncode {\n    display: inline;\n    padding: 2px 6px;\n    background: #34495e;\n    border-radius: 4px;\n}\n\n/* Metadata styling */\n.metadata {\n    margin-top: 20px;\n    padding-top: 15px;\n    border-top: 1px solid #bdc3c7;\n    font-size: 12px;\n    color: #7f8c8d;\n    text-align: center;\n}\n\n.topic {\n    background: #3498db;\n    color: white;\n    padding: 4px 8px;\n    border-radius: 4px;\n    font-weight: 600;\n}\n\n.type {\n    background: #95a5a6;\n    color: white;\n    padding: 4px 8px;\n    border-radius: 4px;\n    margin-left: 8px;\n}\n\n/* Visual emphasis */\nstrong, b {\n    color: #2c3e50;\n    font-weight: 700;\n}\n\nem, i {\n    color: #7f8c8d;\n    font-style: italic;\n}\n\n/* Interactive elements */\ndetails {\n    margin: 10px 0;\n    padding: 10px;\n    background: rgba(52, 152, 219, 0.1);\n    border-radius: 6px;\n    border-left: 4px solid #3498db;\n}\n\nsummary {\n    cursor: pointer;\n    font-weight: 600;\n    color: #3498db;\n    outline: none;\n}\n\n/* Lists */\nul, ol {\n    padding-left: 20px;\n}\n\nli {\n    margin-bottom: 8px;\n}\n\n/* Focus on readability */\np {\n    margin-bottom: 15px;\n}\n\n/* Answer separator */\nhr#answer {\n    border: none;\n    height: 2px;\n    background: linear-gradient(90deg, #3498db, #9b59b6);\n    margin: 20px 0;\n    border-radius: 1px;\n}",
      "flds": [
        {
          "name": "Front",
          "ord": 0,
          "sticky": false,
          "rtl": false,
          "font": "Arial",
          "size": 20
        },
        {
          "name": "Back",
          "ord": 1,
          "sticky": false,
          "rtl": false,
          "font": "Arial",
          "size": 20
        },
        {
          "name": "Topic",
          "ord": 2,
          "sticky": false,
          "rtl": false,
          "font": "Arial",
          "size": 16
        },
        {
          "name": "Type",
          "ord": 3,
          "sticky": false,
          "rtl": false,
          "font": "Arial",
          "size": 14
        }
      ],
      "latexPost": "\\end{document}",
      "latexPre": "\\documentclass[12pt]{article}\\special{papersize=3in,5in}\\usepackage{amssymb,amsmath}\\pagestyle{empty}\\setlength{\\parindent}{0in}\\begin{document}",
      "name": "NLP Rules Optimized",
      "req": [
        [
          0,
          "all",
          [
            0
          ]
        ]
      ],
      "sortf": 0,
      "tags": [],
      "tmpls": [
        {
          "afmt": "{{FrontSide}}<hr id=answer>{{Back}}<br><br><div class='metadata'><span class='topic'>{{Topic}}</span> ‚Ä¢ <span class='type'>{{Type}}</span></div>",
          "bafmt": "",
          "bqfmt": "",
          "did": null,
          "name": "Card 1",
          "ord": 0,
          "qfmt": "{{Front}}"
        }
      ],
      "type": 0,
      "vers": []
    }
  ],
  "notes": [
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>What is self-attention from scratch?",
        "<b>Intuition:</b> Implement self-attention mechanism.<br><b>Symbols:</b> d_k: Key/Query dimension, 4. Return weighted sum of values: Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V<br><b>Formula:</b> Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V",
        "Attention Mechanisms",
        "problem_understanding"
      ],
      "guid": "nlp_152e3182d660e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "problem_understanding"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>What does <code>softmax()</code> do?",
        "<b>Purpose:</b> Numerically stable softmax implementation.",
        "Attention Mechanisms",
        "implementation"
      ],
      "guid": "nlp_fa066a7aca82c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>What does <code>self_attention()</code> do?",
        "<b>Purpose:</b> Implement scaled dot-product self-attention mechanism.",
        "Attention Mechanisms",
        "implementation"
      ],
      "guid": "nlp_3fe4e3018e118",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>What does <code>self_attention_with_mask()</code> do?",
        "<b>Purpose:</b> Self-attention with causal masking (for GPT-style models).",
        "Attention Mechanisms",
        "implementation"
      ],
      "guid": "nlp_147b075ef0e7b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>What does <code>create_causal_mask()</code> do?",
        "<b>Purpose:</b> Create causal mask for autoregressive attention.",
        "Attention Mechanisms",
        "implementation"
      ],
      "guid": "nlp_791eacceedb88",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>What does <code>multi_head_attention()</code> do?",
        "<b>Purpose:</b> Multi-head self-attention (simplified version).",
        "Attention Mechanisms",
        "implementation"
      ],
      "guid": "nlp_c068f7351e8c2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>Write the Key Formula",
        "<h3>def softmax(x: np.ndarray, axis: int = -1) -> np.ndarray:</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Attention Mechanisms",
        "formula"
      ],
      "guid": "nlp_503e3f314b230",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>Write the Attention(Q,K,V)",
        "<h3>softmax(QK^T / ‚àöd_k)V</h3><br><p><i>Scaled dot-product attention: computes attention weights and applies them to values</i></p><br><details><summary>Context</summary><pre>This is the CORE of all transformer models (BERT, GPT, etc.) | Args:</pre></details>",
        "Attention Mechanisms",
        "formula"
      ],
      "guid": "nlp_bc1fa9c945118",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>Write the Key Formula",
        "<h3>attention_weights = softmax(scores, axis=-1)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Attention Mechanisms",
        "formula"
      ],
      "guid": "nlp_4ff78f5b1132a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>Write the Key Formula",
        "<h3>attention_weights = softmax(scores, axis=-1)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Attention Mechanisms",
        "formula"
      ],
      "guid": "nlp_4ff78f5b1132a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>Write the Key Formula",
        "<h3>weights = softmax(scores, axis=-1)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Attention Mechanisms",
        "formula"
      ],
      "guid": "nlp_2964decc10b06",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>What's the Time Complexity?",
        "<b>O(n¬≤d)</b><br><i>See Big O notation reference</i>",
        "Attention Mechanisms",
        "complexity"
      ],
      "guid": "nlp_3dcf672bc1874",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "complexity"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>What's the Space Complexity?",
        "<b>O(n¬≤)</b><br><i>Quadratic time - nested loops, can be slow for large inputs</i>",
        "Attention Mechanisms",
        "complexity"
      ],
      "guid": "nlp_7d87fc96709e5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "complexity"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>üí° Why is this important in interviews?",
        "<p><strong>DEMONSTRATION CODE</strong></p>",
        "Attention Mechanisms",
        "interview_insights"
      ],
      "guid": "nlp_4d69cfb0fec7e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>üîç Why is this important in interviews?",
        "<p><strong>Formula: Attention(Q,K,V) = softmax(QK^T / ‚àöd_k)V</strong></p>",
        "Attention Mechanisms",
        "interview_insights"
      ],
      "guid": "nlp_c751cb27862e7",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>üîç Why is this important in interviews?",
        "<p><strong>Attention allows models to focus on relevant parts of input sequence</strong></p>",
        "Attention Mechanisms",
        "interview_insights"
      ],
      "guid": "nlp_67144390d8d04",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Attention Mechanisms</b><br>üîç Why is this important in interviews?",
        "<p><strong>Self-attention computes relationships between all positions simultaneously</strong></p>",
        "Attention Mechanisms",
        "interview_insights"
      ],
      "guid": "nlp_8bafb7ed76301",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "attention_mechanisms",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>What does <code>create_bow_vector()</code> do?",
        "<b>Purpose:</b> Create bag-of-words representation from scratch.",
        "Bow Vectors",
        "implementation"
      ],
      "guid": "nlp_2f8d0fb9b28c8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>What does <code>cosine_similarity()</code> do?",
        "<b>Purpose:</b> Calculate cosine similarity between two BoW vectors.",
        "Bow Vectors",
        "implementation"
      ],
      "guid": "nlp_c063da355c1a6",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>What does <code>find_most_similar()</code> do?",
        "<b>Purpose:</b> Find document most similar to query document.",
        "Bow Vectors",
        "implementation"
      ],
      "guid": "nlp_f51b2b00e43ed",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>What does <code>analyze_vocabulary_distribution()</code> do?",
        "<b>Purpose:</b> Analyze vocabulary characteristics - good for follow-up questions.",
        "Bow Vectors",
        "implementation"
      ],
      "guid": "nlp_538434f3ce91b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>Write the similarity",
        "<h3>cosine_similarity(query_vector, doc_vector)</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre># Don't compare document with itself | if i != query_idx: | # Track the highest similarity found</pre></details>",
        "Bow Vectors",
        "formula"
      ],
      "guid": "nlp_d55f22e6f1cc8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>Write the sim",
        "<h3>cosine_similarity(vectors[i], vectors[j])</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre>for i in range(len(documents)): | for j in range(i + 1, len(documents)): | print(f\"  Doc {i} ‚Üî Doc {j}: {sim:.3f}\")</pre></details>",
        "Bow Vectors",
        "formula"
      ],
      "guid": "nlp_6598fe189167d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>Write the sim_score",
        "<h3>cosine_similarity(vectors[query_idx], vectors[most_similar])</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre># Calculate and show the similarity score | print(f\"Similarity score: {sim_score:.3f}\")</pre></details>",
        "Bow Vectors",
        "formula"
      ],
      "guid": "nlp_82ad82ad69368",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>What's the Time Complexity?",
        "<b>O(d √ó n √ó v)</b><br><i>See Big O notation reference</i>",
        "Bow Vectors",
        "complexity"
      ],
      "guid": "nlp_79d0f8097a625",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "complexity"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Bow Vectors</b><br>What's the Space Complexity?",
        "<b>O(d √ó v)</b><br><i>See Big O notation reference</i>",
        "Bow Vectors",
        "complexity"
      ],
      "guid": "nlp_103f2daf77b26",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "bow_vectors",
        "complexity"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Cnn Text</b><br>What does <code>text_to_sequence()</code> do?",
        "<b>Purpose:</b> Convert text to padded integer sequence.",
        "Cnn Text",
        "implementation"
      ],
      "guid": "nlp_1e93c6d402de9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "cnn_text",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Cnn Text</b><br>What does <code>embedding_lookup()</code> do?",
        "<b>Purpose:</b> Look up embeddings for sequence.",
        "Cnn Text",
        "implementation"
      ],
      "guid": "nlp_19f2226b339a9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "cnn_text",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Cnn Text</b><br>What does <code>conv1d()</code> do?",
        "<b>Purpose:</b> Apply 1D convolution with kernel size 3.",
        "Cnn Text",
        "implementation"
      ],
      "guid": "nlp_7bc94adae63b1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "cnn_text",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Cnn Text</b><br>What does <code>max_pool()</code> do?",
        "<b>Purpose:</b> Global max pooling.",
        "Cnn Text",
        "implementation"
      ],
      "guid": "nlp_6da4e51bf622a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "cnn_text",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Cnn Text</b><br>What does <code>sigmoid()</code> do?",
        "<b>Purpose:</b> Sigmoid activation.",
        "Cnn Text",
        "implementation"
      ],
      "guid": "nlp_9a579f6e85061",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "cnn_text",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Cnn Text</b><br>What does <code>text_cnn_predict()</code> do?",
        "<b>Purpose:</b> CNN forward pass for text classification.",
        "Cnn Text",
        "implementation"
      ],
      "guid": "nlp_48c5487164524",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "cnn_text",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Cnn Text</b><br>What does <code>create_sample_weights()</code> do?",
        "<b>Purpose:</b> Create sample weights for demonstration.",
        "Cnn Text",
        "implementation"
      ],
      "guid": "nlp_48d23ef28eb42",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "cnn_text",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Cnn Text</b><br>What does <code>test_cnn()</code> do?",
        "",
        "Cnn Text",
        "implementation"
      ],
      "guid": "nlp_78e7cc39da9fa",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "cnn_text",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Embeddings</b><br>What does <code>sigmoid()</code> do?",
        "<b>Purpose:</b> Sigmoid activation function: œÉ(x) = 1 / (1 + e^(-x))",
        "Embeddings",
        "implementation"
      ],
      "guid": "nlp_c67e81389ead6",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "embeddings",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Embeddings</b><br>What does <code>dot_product()</code> do?",
        "<b>Purpose:</b> Calculate dot product between two vectors.",
        "Embeddings",
        "implementation"
      ],
      "guid": "nlp_a0530913ef6f4",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "embeddings",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Embeddings</b><br>What does <code>skipgram_step()</code> do?",
        "<b>Purpose:</b> Perform one training step of Skip-gram Word2Vec.",
        "Embeddings",
        "implementation"
      ],
      "guid": "nlp_1efe68a137988",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "embeddings",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Embeddings</b><br>What does <code>word_similarity()</code> do?",
        "<b>Purpose:</b> Calculate cosine similarity between two word embeddings.",
        "Embeddings",
        "implementation"
      ],
      "guid": "nlp_d2d3e721beb43",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "embeddings",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Embeddings</b><br>What does <code>find_most_similar()</code> do?",
        "<b>Purpose:</b> Find k most similar words to target word.",
        "Embeddings",
        "implementation"
      ],
      "guid": "nlp_03087b03f9dd5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "embeddings",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Embeddings</b><br>üí° Why is this important in interviews?",
        "<p><strong>DEMONSTRATION</strong></p>",
        "Embeddings",
        "interview_insights"
      ],
      "guid": "nlp_51a2b5d9c2a2f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "embeddings",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Embeddings</b><br>üîç Why is this important in interviews?",
        "<p><strong>Embeddings map discrete tokens to dense continuous vectors</strong></p>",
        "Embeddings",
        "interview_insights"
      ],
      "guid": "nlp_105533b9a9fd1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "embeddings",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Embeddings</b><br>üîç Why is this important in interviews?",
        "<p><strong>Similar words have similar embeddings in vector space</strong></p>",
        "Embeddings",
        "interview_insights"
      ],
      "guid": "nlp_838f84b1b5a60",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "embeddings",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>What does <code>spell_check_approach()</code> do?",
        "<b>Purpose:</b> KEY: Use edit distance + frequency ranking",
        "Example Anki Refactor",
        "implementation"
      ],
      "guid": "nlp_534bb8918d474",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>What does <code>edit_distance_recursive()</code> do?",
        "<b>Purpose:</b> FORMULA: ED(i,j) = min(",
        "Example Anki Refactor",
        "implementation"
      ],
      "guid": "nlp_8d0f0d9dfea80",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>What does <code>edit_distance_dp()</code> do?",
        "<b>Purpose:</b> COMPLEXITY: O(m*n) time, O(m*n) space",
        "Example Anki Refactor",
        "implementation"
      ],
      "guid": "nlp_eb81e7b42915e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>What does <code>find_candidates()</code> do?",
        "<b>Purpose:</b> STRATEGY: Only check words within length ¬±2",
        "Example Anki Refactor",
        "implementation"
      ],
      "guid": "nlp_fc618077a09fe",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>What does <code>rank_by_frequency()</code> do?",
        "<b>Purpose:</b> FORMULA: score = frequency / (distance + 1)",
        "Example Anki Refactor",
        "implementation"
      ],
      "guid": "nlp_d106b6c056514",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>What does <code>spell_checker()</code> do?",
        "<b>Purpose:</b> INTERVIEW: Mention trade-offs:<br><b>Edge:</b> Already correct word",
        "Example Anki Refactor",
        "implementation"
      ],
      "guid": "nlp_ffe31de0952f0",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>What does <code>example_usage()</code> do?",
        "<b>Purpose:</b> EXAMPLE:",
        "Example Anki Refactor",
        "implementation"
      ],
      "guid": "nlp_5eb3732c0eb47",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>Write the Key Formula",
        "<h3>- rank_by_frequency: O(k log k) where k=candidates</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Example Anki Refactor",
        "formula"
      ],
      "guid": "nlp_26f2b428c1f29",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>Key concept:",
        "<p>from typing import Dict, List, Tuple\n\n# Card 1: Algorithm Overview\ndef spell_check_approach():</p>",
        "Example Anki Refactor",
        "concepts"
      ],
      "guid": "nlp_16246265cf09b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "concepts"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Example Anki Refactor</b><br>Key concept:",
        "<p>from typing import Dict, List, Tuple\n\n# Card 1: Algorithm Overview\ndef spell_check_approach():</p>",
        "Example Anki Refactor",
        "concepts"
      ],
      "guid": "nlp_16246265cf09b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "example_anki_refactor",
        "concepts"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>What does <code>add_classification_head()</code> do?",
        "<b>Purpose:</b> Add classification head to pretrained LLM.",
        "Fine Tuning",
        "implementation"
      ],
      "guid": "nlp_c480f9d16377e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>What does <code>compute_classification_loss()</code> do?",
        "<b>Purpose:</b> Compute cross-entropy loss with numerical stability.",
        "Fine Tuning",
        "implementation"
      ],
      "guid": "nlp_1d4fa405040aa",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>What does <code>freeze_layers()</code> do?",
        "<b>Purpose:</b> Mark layers as frozen (simulate requires_grad=False).",
        "Fine Tuning",
        "implementation"
      ],
      "guid": "nlp_b8af2257c0c23",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>What does <code>fine_tuning_step()</code> do?",
        "<b>Purpose:</b> Single fine-tuning step (forward + backward).",
        "Fine Tuning",
        "implementation"
      ],
      "guid": "nlp_ed511ac6c2129",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>What does <code>compute_accuracy()</code> do?",
        "<b>Purpose:</b> Compute classification accuracy.",
        "Fine Tuning",
        "implementation"
      ],
      "guid": "nlp_fe54e255cf165",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>What does <code>lora_approximation()</code> do?",
        "<b>Purpose:</b> Simulate LoRA (Low-Rank Adaptation) decomposition.",
        "Fine Tuning",
        "implementation"
      ],
      "guid": "nlp_97436c5cfd41d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>What does <code>test_fine_tuning()</code> do?",
        "<b>Purpose:</b> Demonstrate fine-tuning workflow.",
        "Fine Tuning",
        "implementation"
      ],
      "guid": "nlp_26d1c9fd9ed3a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>batch_size, num_classes = logits.shape</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_a741cc0692feb",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>logits_stable = logits - np.max(logits, axis=1, keepdims=True)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_91a40d6b86ac7",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>exp_logits = np.exp(logits_stable)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_ffa3e2e76281a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_86d4aef9363cf",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>Add small epsilon</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_b7bd4c6e30da1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>logits = pretrained_output @ cls_head['W_cls'] + cls_head['b_cls']</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_e7ebabd98d190",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>loss = compute_classification_loss(logits, labels)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_c5d991d3c02fd",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>logits_stable = logits - np.max(logits, axis=1, keepdims=True)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_91a40d6b86ac7",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>exp_logits = np.exp(logits_stable)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_ffa3e2e76281a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_86d4aef9363cf",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>grad_logits = probs.copy()</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_24dcb15502eee",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>grad_logits[i, labels[i]] -= 1</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_5a4f611efd855",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>grad_logits /= batch_size</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_4f94396e6e9e0",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>grad_W_cls = pretrained_output.T @ grad_logits</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_5f8846252dc81",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>grad_b_cls = np.sum(grad_logits, axis=0)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_02812982bf37a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>grad_pretrained = grad_logits @ cls_head['W_cls'].T</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_0eb7f9a274346",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>predictions = np.argmax(logits, axis=1)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_71cc54d0bfe6d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>logits = x @ cls_head['W_cls'] + cls_head['b_cls']</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_1dba88e1567fe",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Fine Tuning</b><br>Write the Key Formula",
        "<h3>accuracy = compute_accuracy(logits, labels)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Fine Tuning",
        "formula"
      ],
      "guid": "nlp_ca684cd947e8b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "fine_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Gpt Implementation</b><br>What does <code>gelu()</code> do?",
        "<b>Purpose:</b> GELU activation function used in GPT.",
        "Gpt Implementation",
        "implementation"
      ],
      "guid": "nlp_9b4b56fa5c3ce",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "gpt_implementation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Gpt Implementation</b><br>What does <code>layer_norm()</code> do?",
        "<b>Purpose:</b> Apply layer normalization.",
        "Gpt Implementation",
        "implementation"
      ],
      "guid": "nlp_17bbe4bff4c33",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "gpt_implementation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Gpt Implementation</b><br>What does <code>causal_self_attention()</code> do?",
        "<b>Purpose:</b> Causal self-attention for GPT.",
        "Gpt Implementation",
        "implementation"
      ],
      "guid": "nlp_ca0f9b1b5cee9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "gpt_implementation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Gpt Implementation</b><br>What does <code>feed_forward()</code> do?",
        "<b>Purpose:</b> Feed-forward network with GELU activation.",
        "Gpt Implementation",
        "implementation"
      ],
      "guid": "nlp_03724b1e21656",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "gpt_implementation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Gpt Implementation</b><br>What does <code>gpt_block()</code> do?",
        "<b>Purpose:</b> Single GPT transformer block.",
        "Gpt Implementation",
        "implementation"
      ],
      "guid": "nlp_6ef50373511b0",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "gpt_implementation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Gpt Implementation</b><br>What does <code>create_gpt_weights()</code> do?",
        "<b>Purpose:</b> Create sample weights for GPT block.",
        "Gpt Implementation",
        "implementation"
      ],
      "guid": "nlp_a547ace2d721d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "gpt_implementation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Gpt Implementation</b><br>What does <code>positional_encoding()</code> do?",
        "<b>Purpose:</b> Create sinusoidal positional encodings.",
        "Gpt Implementation",
        "implementation"
      ],
      "guid": "nlp_8a5c697407154",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "gpt_implementation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Gpt Implementation</b><br>What does <code>simple_gpt_forward()</code> do?",
        "<b>Purpose:</b> Forward pass through a simple GPT model.",
        "Gpt Implementation",
        "implementation"
      ],
      "guid": "nlp_16efeb933f57b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "gpt_implementation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>What does <code>format_instruction_data()</code> do?",
        "<b>Purpose:</b> Format instruction-response pair for training.",
        "Instruction Tuning",
        "implementation"
      ],
      "guid": "nlp_38e9ac29c03d5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>What does <code>tokenize_instruction_response()</code> do?",
        "<b>Purpose:</b> Tokenize formatted instruction-response and return instruction length.",
        "Instruction Tuning",
        "implementation"
      ],
      "guid": "nlp_a1a1978bab6a4",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>What does <code>compute_instruction_loss()</code> do?",
        "<b>Purpose:</b> Compute loss only on response tokens.",
        "Instruction Tuning",
        "implementation"
      ],
      "guid": "nlp_33984f3c1b873",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>What does <code>create_instruction_dataset()</code> do?",
        "<b>Purpose:</b> Create instruction tuning dataset.",
        "Instruction Tuning",
        "implementation"
      ],
      "guid": "nlp_e6ceace9c9a5c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>What does <code>evaluate_instruction_following()</code> do?",
        "<b>Purpose:</b> Simple evaluation metrics for instruction following.",
        "Instruction Tuning",
        "implementation"
      ],
      "guid": "nlp_b0fe2dd29f0e9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>What does <code>sampling_strategies()</code> do?",
        "<b>Purpose:</b> Implement different sampling strategies for text generation.",
        "Instruction Tuning",
        "implementation"
      ],
      "guid": "nlp_719ebf944c8d7",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>response_logits = model_output[instruction_length:]</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_6fc4b56fadaf7",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>logits = response_logits[i]</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_ae862aa290a0c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>max_logit = np.max(logits)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_9415f238f7b1c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>exp_logits = np.exp(logits - max_logit)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_128507bf43be3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>probs = exp_logits / np.sum(exp_logits)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_44447f56b686c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>loss += -np.log(probs[target_token] + 1e-10)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_ae41e52787fdc",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>def sampling_strategies(logits: np.ndarray, temperature: float = 1.0,</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_7a995c0b2f3d8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>logits = logits / temperature</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_b47e440b541d5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>max_logit = np.max(logits)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_9415f238f7b1c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>exp_logits = np.exp(logits - max_logit)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_128507bf43be3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>probs = exp_logits / np.sum(exp_logits)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_44447f56b686c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>mock_logits = np.random.randn(seq_len, vocab_size)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_e844761b67f70",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>loss = compute_instruction_loss(mock_logits, mock_targets, instruction_len)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_f99b677940224",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>5 possible tokens</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_f5068f2319b1e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>Write the Key Formula",
        "<h3>token = sampling_strategies(sample_logits, **params)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Instruction Tuning",
        "formula"
      ],
      "guid": "nlp_1c73fb99b2355",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Instruction Tuning</b><br>üî• Edge case: Empty Collection",
        "<pre><code>response_targets return 0.0</code></pre>",
        "Instruction Tuning",
        "edge_cases"
      ],
      "guid": "nlp_8e82fbeb2e9d2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "instruction_tuning",
        "edge_cases"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>What does <code>softmax()</code> do?",
        "<b>Purpose:</b> Convert logits to probabilities with temperature scaling.",
        "Llm Fundamentals",
        "implementation"
      ],
      "guid": "nlp_11a888dd0ef87",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>What does <code>sample_token()</code> do?",
        "<b>Purpose:</b> Sample next token using different strategies.",
        "Llm Fundamentals",
        "implementation"
      ],
      "guid": "nlp_d790390cfc2d3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>What does <code>generate_text()</code> do?",
        "<b>Purpose:</b> Generate text using autoregressive language model.",
        "Llm Fundamentals",
        "implementation"
      ],
      "guid": "nlp_4448e9e254d08",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>What does <code>beam_search()</code> do?",
        "<b>Purpose:</b> Implement beam search for finding high-probability sequences.",
        "Llm Fundamentals",
        "implementation"
      ],
      "guid": "nlp_38a69b9953bc8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>What does <code>mock_language_model()</code> do?",
        "<b>Purpose:</b> Mock language model that returns random logits.",
        "Llm Fundamentals",
        "implementation"
      ],
      "guid": "nlp_3b3ca275b01ef",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>def softmax(logits: List[float], temperature: float = 1.0) -> List[float]:</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_0cf1d14d61216",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>logits = [l / temperature for l in logits]</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_bedbf9d1ec8f2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>max_logit = max(logits)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_765e7f72ba49c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>exp_logits = [math.exp(l - max_logit) for l in logits]</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_4bead9231de72",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>sum_exp = sum(exp_logits)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_e366c77a9194f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>logits = model_fn(current_tokens)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_09faf8227af7b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>probs = softmax(logits, temperature)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_54b0cdade4934",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>logits = model_fn(sequence)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_aa3a35b9b6604",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>probs = softmax(logits)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_3c5e8ef055833",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>new_log_prob = log_prob + math.log(probs[token_id] + 1e-10)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_3e08419f8167e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>probability = math.exp(log_prob)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_0de0ac599255a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>Strong preference for token 0</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_0bec9edeefe8c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>probs = softmax(test_logits, temperature=temp)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_eeb5fc6f3d9cf",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>Write the Key Formula",
        "<h3>entropy = -sum(p * math.log(p + 1e-10) for p in probs)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Llm Fundamentals",
        "formula"
      ],
      "guid": "nlp_c00d77a04d421",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>üîç Why is this important in interviews?",
        "<p><strong>LLMs predict next token based on previous context</strong></p>",
        "Llm Fundamentals",
        "interview_insights"
      ],
      "guid": "nlp_e156e41a22b56",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Llm Fundamentals</b><br>üîç Why is this important in interviews?",
        "<p><strong>Temperature controls randomness in generation</strong></p>",
        "Llm Fundamentals",
        "interview_insights"
      ],
      "guid": "nlp_c6f2501cdcfd2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "llm_fundamentals",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>What does <code>calculate_perplexity()</code> do?",
        "<b>Purpose:</b> Calculate perplexity from model probabilities.",
        "Model Evaluation",
        "implementation"
      ],
      "guid": "nlp_1ae6042e2c464",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>What does <code>get_ngrams()</code> do?",
        "<b>Purpose:</b> Extract n-grams from text.",
        "Model Evaluation",
        "implementation"
      ],
      "guid": "nlp_dc11d3db3807a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>What does <code>compute_bleu_score()</code> do?",
        "<b>Purpose:</b> Compute BLEU score for text generation evaluation.",
        "Model Evaluation",
        "implementation"
      ],
      "guid": "nlp_2b1c3aeb97d85",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>What does <code>calculate_cross_entropy_loss()</code> do?",
        "<b>Purpose:</b> Calculate cross-entropy loss from logits.",
        "Model Evaluation",
        "implementation"
      ],
      "guid": "nlp_c712464dc707b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>What does <code>evaluate_generation_quality()</code> do?",
        "<b>Purpose:</b> Comprehensive evaluation of generated text quality.",
        "Model Evaluation",
        "implementation"
      ],
      "guid": "nlp_b3d749d07d168",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>log_likelihood = 0.0</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_2a9096fc2f56d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>log_likelihood += math.log(max(prob, 1e-10))</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_3fdbfcb3f3773",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>Perplexity = exp(-avg_log_likelihood)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_8fa36acad9fdf",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>avg_log_likelihood = log_likelihood / num_tokens</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_d0600d019cbf5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>perplexity = math.exp(-avg_log_likelihood)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_1e235572096dc",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>if not logits or not targets or len(logits) != len(targets):</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_ac8326cabacd5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>max_logit = max(logit_vec)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_c495cc44e9ab8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>exp_logits = [math.exp(logit - max_logit) for logit in logit_vec]</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_ca435a1394414",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>sum_exp = sum(exp_logits)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_df7ef7ba5e4f1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>prob = exp_logits[target] / sum_exp</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_9ce61fe1dbb8d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>total_loss += -math.log(max(prob, 1e-10))</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_694eb534e388f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>5 possible next tokens</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_9884514a87ffa",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>Nearly deterministic</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_b0e3dd811cac7",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>random_sample = sampling_strategies(logits, temperature=1.0)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_2e8eaefe080ea",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>top_k_sample = sampling_strategies(logits, temperature=1.0, top_k=3)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_11e4959157821",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>Write the Key Formula",
        "<h3>top_p_sample = sampling_strategies(logits, temperature=1.0, top_p=0.8)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Model Evaluation",
        "formula"
      ],
      "guid": "nlp_347ecf4e7c141",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Model Evaluation</b><br>üîç Why is this important in interviews?",
        "<p><strong>Compute BLEU score for text generation evaluation.</strong></p>",
        "Model Evaluation",
        "interview_insights"
      ],
      "guid": "nlp_85e21a2aba637",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "model_evaluation",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ner</b><br>What does <code>extract_entities()</code> do?",
        "<b>Purpose:</b> Extract named entities using spaCy.",
        "Ner",
        "implementation"
      ],
      "guid": "nlp_670889baf6c64",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ner",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ner</b><br>What does <code>extract_custom_entities()</code> do?",
        "<b>Purpose:</b> Extract custom entities like emails, phones, URLs using regex.",
        "Ner",
        "implementation"
      ],
      "guid": "nlp_95e4fc0905e4c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ner",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ner</b><br>What does <code>extract_entities_with_context()</code> do?",
        "<b>Purpose:</b> Extract entities with surrounding context.",
        "Ner",
        "implementation"
      ],
      "guid": "nlp_4147c0f2388e6",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ner",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ner</b><br>What does <code>extract_entity_relationships()</code> do?",
        "<b>Purpose:</b> Extract simple relationships between entities.",
        "Ner",
        "implementation"
      ],
      "guid": "nlp_4bf722b31700e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ner",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ner</b><br>What does <code>resolve_entity_coreferences()</code> do?",
        "<b>Purpose:</b> Simple coreference resolution for entities (e.g., 'Apple' -> 'Apple Inc.')",
        "Ner",
        "implementation"
      ],
      "guid": "nlp_3545f181b04ab",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ner",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ner</b><br>What does <code>extract_entities_with_confidence()</code> do?",
        "<b>Purpose:</b> Extract entities with confidence scores (using spaCy's scores if available).",
        "Ner",
        "implementation"
      ],
      "guid": "nlp_7becef6e37b45",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ner",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ner</b><br>üîç Why is this important in interviews?",
        "<p><strong>Simple coreference resolution for entities (e.g., 'Apple' -> 'Apple Inc.')</strong></p>",
        "Ner",
        "interview_insights"
      ],
      "guid": "nlp_e9c4ab0be5066",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ner",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ner</b><br>üîç Why is this important in interviews?",
        "<p><strong>Extract entities with confidence scores (using spaCy's scores if available).</strong></p>",
        "Ner",
        "interview_insights"
      ],
      "guid": "nlp_2f2bb18301fc0",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ner",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ngrams</b><br>What does <code>build_bigram_model()</code> do?",
        "<b>Purpose:</b> Build bigram language model with probabilities.",
        "Ngrams",
        "implementation"
      ],
      "guid": "nlp_f0ab31536c09b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ngrams",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ngrams</b><br>What does <code>generate_text()</code> do?",
        "<b>Purpose:</b> Generate text using bigram model (deterministic - pick most probable).",
        "Ngrams",
        "implementation"
      ],
      "guid": "nlp_88fdd48b38821",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ngrams",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Ngrams</b><br>What does <code>calculate_probability()</code> do?",
        "<b>Purpose:</b> Calculate probability of text under the model.",
        "Ngrams",
        "implementation"
      ],
      "guid": "nlp_f417da723a5a2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "ngrams",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>gradient_check()</code> do?",
        "<b>Purpose:</b> Perform gradient checking to verify backpropagation implementation.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_23bbbebe6139b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>generate_xor_data()</code> do?",
        "<b>Purpose:</b> Generate XOR problem data.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_0b015c52a51a0",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>generate_spiral_data()</code> do?",
        "<b>Purpose:</b> Generate spiral classification data.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_a3c0152531fb1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>plot_decision_boundary()</code> do?",
        "<b>Purpose:</b> Plot decision boundary for 2D data.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_eaa692095825f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>sigmoid()</code> do?",
        "<b>Purpose:</b> Sigmoid activation function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_01a4f4651b5c3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>sigmoid_derivative()</code> do?",
        "<b>Purpose:</b> Derivative of sigmoid function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_2ad872a151ed1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>tanh()</code> do?",
        "<b>Purpose:</b> Hyperbolic tangent activation function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_68400b5867564",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>tanh_derivative()</code> do?",
        "<b>Purpose:</b> Derivative of tanh function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_638f70c18da7f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>relu()</code> do?",
        "<b>Purpose:</b> ReLU activation function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_d38147b076347",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>relu_derivative()</code> do?",
        "<b>Purpose:</b> Derivative of ReLU function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_1f87772590e9f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>leaky_relu()</code> do?",
        "<b>Purpose:</b> Leaky ReLU activation function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_9d5a3e1a79963",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>leaky_relu_derivative()</code> do?",
        "<b>Purpose:</b> Derivative of Leaky ReLU function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_6fb15582605b2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>softmax()</code> do?",
        "<b>Purpose:</b> Softmax activation function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_26dc74090b4d3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>__init__()</code> do?",
        "",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_84ee427dad686",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>_get_activation_functions()</code> do?",
        "<b>Purpose:</b> Get activation function and its derivative.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_03fe6926d884f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>forward()</code> do?",
        "<b>Purpose:</b> Forward propagation.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_1e3be66c6c0c3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>compute_cost()</code> do?",
        "<b>Purpose:</b> Compute binary cross-entropy loss.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_707a024e232d9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>backward()</code> do?",
        "<b>Purpose:</b> Backward propagation.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_3461f45815407",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>train()</code> do?",
        "<b>Purpose:</b> Train the perceptron.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_434ce3710222b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>predict()</code> do?",
        "<b>Purpose:</b> Make predictions.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_0832a2e9baeef",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>__init__()</code> do?",
        "",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_84ee427dad686",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>_get_activation_functions()</code> do?",
        "<b>Purpose:</b> Get activation function and its derivative.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_03fe6926d884f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>forward()</code> do?",
        "<b>Purpose:</b> Forward propagation through the network.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_fbca78463618c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>compute_cost()</code> do?",
        "<b>Purpose:</b> Compute cost function.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_093d36b8c82fb",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>backward()</code> do?",
        "<b>Purpose:</b> Backward propagation through the network.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_0757e0c964412",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>train()</code> do?",
        "<b>Purpose:</b> Train the neural network.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_1beab6d650629",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>predict()</code> do?",
        "<b>Purpose:</b> Make predictions.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_0832a2e9baeef",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>predict_proba()</code> do?",
        "<b>Purpose:</b> Get prediction probabilities.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_69bdb8b366fef",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>compute_accuracy()</code> do?",
        "<b>Purpose:</b> Compute accuracy.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_a5acb6eff55cc",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>__init__()</code> do?",
        "",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_84ee427dad686",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>What does <code>update()</code> do?",
        "<b>Purpose:</b> Update network parameters using Adam optimizer.",
        "Neural Fundamentals",
        "implementation"
      ],
      "guid": "nlp_552ea6a1991be",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>Write the Key Formula",
        "<h3>elif activation == 'softmax':</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Neural Fundamentals",
        "formula"
      ],
      "guid": "nlp_fcf9119d5dbe3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>Write the Key Formula",
        "<h3>if self.output_activation == 'softmax':</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Neural Fundamentals",
        "formula"
      ],
      "guid": "nlp_544d340740818",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>Write the Key Formula",
        "<h3>return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Neural Fundamentals",
        "formula"
      ],
      "guid": "nlp_3789f7cafacb9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Neural Fundamentals</b><br>Write the Key Formula",
        "<h3>if self.output_activation == 'softmax' and y_true.shape[1] > 1:</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Neural Fundamentals",
        "formula"
      ],
      "guid": "nlp_40f4ee65b5ff2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "neural_fundamentals",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Pos Tagging</b><br>What does <code>pos_tag_text()</code> do?",
        "<b>Purpose:</b> POS tag text using NLTK's default tagger (Penn Treebank tagset).",
        "Pos Tagging",
        "implementation"
      ],
      "guid": "nlp_c657840732302",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "pos_tagging",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Pos Tagging</b><br>What does <code>extract_pos()</code> do?",
        "<b>Purpose:</b> Extract words with specific POS tags.",
        "Pos Tagging",
        "implementation"
      ],
      "guid": "nlp_5a117b71517c5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "pos_tagging",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Pos Tagging</b><br>What does <code>find_noun_phrases()</code> do?",
        "<b>Purpose:</b> Extract simple noun phrases using POS patterns.",
        "Pos Tagging",
        "implementation"
      ],
      "guid": "nlp_c49616d07a2df",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "pos_tagging",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Pos Tagging</b><br>What does <code>analyze_word_ambiguity()</code> do?",
        "<b>Purpose:</b> Analyze POS tag distribution for an ambiguous word.",
        "Pos Tagging",
        "implementation"
      ],
      "guid": "nlp_134c58b0c3f4b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "pos_tagging",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Pos Tagging</b><br>What does <code>compare_taggers()</code> do?",
        "<b>Purpose:</b> Compare different POS taggers on the same text.",
        "Pos Tagging",
        "implementation"
      ],
      "guid": "nlp_8f695083ac7d6",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "pos_tagging",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Pos Tagging</b><br>What does <code>pos_tag_with_confidence()</code> do?",
        "<b>Purpose:</b> POS tag with confidence scores (simplified version).",
        "Pos Tagging",
        "implementation"
      ],
      "guid": "nlp_1e68d193f4913",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "pos_tagging",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Pos Tagging</b><br>üîç Why is this important in interviews?",
        "<p><strong>POS tag with confidence scores (simplified version).</strong></p>",
        "Pos Tagging",
        "interview_insights"
      ],
      "guid": "nlp_6d447e4475daf",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "pos_tagging",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>extract_entities_regex()</code> do?",
        "<b>Purpose:</b> Extract various entities using regex patterns.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_eb3f37685237d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>sentence_segmentation()</code> do?",
        "<b>Purpose:</b> Segment text into sentences using regex, handling abbreviations.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_a7aa066fd04d3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>pattern_based_ner()</code> do?",
        "<b>Purpose:</b> Custom named entity recognition using regex patterns.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_012286e606c2b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>clean_text_regex()</code> do?",
        "<b>Purpose:</b> Apply multiple regex cleaning rules to text.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_3cf36c62ea4b8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>extract_structured_data()</code> do?",
        "<b>Purpose:</b> Extract structured information like addresses, names, etc.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_4de7ecca767be",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>build_custom_tokenizer()</code> do?",
        "<b>Purpose:</b> Build a custom tokenizer based on regex patterns.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_1dffc6db1d906",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>validate_extracted_data()</code> do?",
        "<b>Purpose:</b> Validate extracted entities and filter out false positives.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_d0b75bf57b3a8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>optimize_regex_performance()</code> do?",
        "<b>Purpose:</b> Optimized regex extraction for large texts.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_b4f72c9894681",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Regex Nlp</b><br>What does <code>custom_tokenize()</code> do?",
        "<b>Purpose:</b> Tokenize text using custom patterns.",
        "Regex Nlp",
        "implementation"
      ],
      "guid": "nlp_ec50ce039eb21",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "regex_nlp",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Sentiment Analysis</b><br>What does <code>analyze_sentiment()</code> do?",
        "<b>Purpose:</b> Analyze sentiment using rule-based approach (VADER-style).",
        "Sentiment Analysis",
        "implementation"
      ],
      "guid": "nlp_fa4da205e4158",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "sentiment_analysis",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Sentiment Analysis</b><br>What does <code>classify_sentiment()</code> do?",
        "<b>Purpose:</b> Convert sentiment scores to simple classification.",
        "Sentiment Analysis",
        "implementation"
      ],
      "guid": "nlp_1c87a4da33aea",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "sentiment_analysis",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Sequence Models</b><br>What does <code>sigmoid()</code> do?",
        "",
        "Sequence Models",
        "implementation"
      ],
      "guid": "nlp_c20f7ac3b5c40",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "sequence_models",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Sequence Models</b><br>What does <code>tanh()</code> do?",
        "",
        "Sequence Models",
        "implementation"
      ],
      "guid": "nlp_d25dafa792c42",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "sequence_models",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Sequence Models</b><br>What does <code>dot_product()</code> do?",
        "",
        "Sequence Models",
        "implementation"
      ],
      "guid": "nlp_5f2efbfc041fa",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "sequence_models",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Sequence Models</b><br>What does <code>lstm_cell()</code> do?",
        "<b>Purpose:</b> Single LSTM cell forward pass.",
        "Sequence Models",
        "implementation"
      ],
      "guid": "nlp_8f7fa1de755fa",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "sequence_models",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Sequence Models</b><br>What does <code>lstm_sentiment()</code> do?",
        "<b>Purpose:</b> Run LSTM over sequence and classify sentiment.",
        "Sequence Models",
        "implementation"
      ],
      "guid": "nlp_b345b938bff9b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "sequence_models",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Sequence Models</b><br>Write the Key Formula",
        "<h3>logit = dot_product(h_t, weights['W_output']) + weights['b_output']</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Sequence Models",
        "formula"
      ],
      "guid": "nlp_7886e8219d896",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "sequence_models",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What is text similarity metrics?",
        "<b>Intuition:</b> - Compare bag-of-words vs embeddings approaches<br><b>Formula:</b> cosine_sim = 0.45 (bag-of-words)",
        "Similarity",
        "problem_understanding"
      ],
      "guid": "nlp_57c854f3e0f54",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "problem_understanding"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>tokenize()</code> do?",
        "<b>Purpose:</b> Simple tokenization.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_c9946bde291ae",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>cosine_similarity()</code> do?",
        "<b>Purpose:</b> Calculate cosine similarity between two texts.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_58b25c11515b7",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>jaccard_similarity()</code> do?",
        "<b>Purpose:</b> Calculate Jaccard similarity (intersection over union).",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_fde3e6c53572e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>get_ngrams()</code> do?",
        "<b>Purpose:</b> Extract n-grams from text.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_f9ae25ddfac38",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>semantic_similarity()</code> do?",
        "<b>Purpose:</b> Calculate semantic similarity using embeddings.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_1dd696e663485",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>levenshtein_distance()</code> do?",
        "<b>Purpose:</b> Calculate Levenshtein (edit) distance between texts.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_5f3e7cdb36b05",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>find_near_duplicates()</code> do?",
        "<b>Purpose:</b> Find near-duplicate texts using MinHash.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_363955c642599",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>similarity_matrix()</code> do?",
        "<b>Purpose:</b> Compute pairwise similarity matrix for multiple texts.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_83d403866972a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>__init__()</code> do?",
        "",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_1978f6b856901",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>_generate_hash_functions()</code> do?",
        "<b>Purpose:</b> Generate hash functions for MinHash.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_f5acf50396a28",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>get_shingles()</code> do?",
        "<b>Purpose:</b> Convert text to shingles (n-grams).",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_d41b512130161",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>compute_minhash()</code> do?",
        "<b>Purpose:</b> Compute MinHash signature for text.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_31dd242f5f1fa",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>What does <code>jaccard_similarity_minhash()</code> do?",
        "<b>Purpose:</b> Estimate Jaccard similarity from MinHash signatures.",
        "Similarity",
        "implementation"
      ],
      "guid": "nlp_abc059d05c5b3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the def cosine_similarity(text1: str, text2: str, method",
        "<h3>'tfidf') -> float:</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre>\"\"\"Calculate cosine similarity between two texts.\"\"\" | if method == 'tfidf':</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_f9f4f8942e526",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the similarity",
        "<h3>sklearn_cosine([embeddings[0]], [embeddings[1]])[0][0]</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre># Calculate cosine similarity | return float(similarity)</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_3e4f3e52a67a8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the return cosine_similarity(text1, text2, method",
        "<h3>'tfidf')</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre>except: | # Ultimate fallback: enhanced bag-of-words</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_5f3bd699f73da",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the def similarity_matrix(texts: List[str], method: str",
        "<h3>'cosine') -> np.ndarray:</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre>\"\"\"Compute pairwise similarity matrix for multiple texts.\"\"\" | n = len(texts)</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_0bc4632919cf3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the if method",
        "<h3>= 'cosine':</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre>matrix[i][j] = 1.0 | else: | sim = cosine_similarity(texts[i], texts[j])</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_5287ac4a0c30a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the sim",
        "<h3>cosine_similarity(texts[i], texts[j])</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre>else: | if method == 'cosine': | elif method == 'jaccard':</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_7073ec594b1e5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the print(f\"Cosine (BoW):     {cosine_similarity(text1, text2, method",
        "<h3>'bow'):.3f}\")</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre># Different similarity metrics | print(f\"Cosine (TF-IDF):  {cosine_similarity(text1, text2, method='tfidf'):.3f}\") | print(f\"Jaccard (words):  {jaccard_similarity(text1, text2, ngram_size=1):.3f}\")</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_e4f2c299123d3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the print(f\"Cosine (TF-IDF):  {cosine_similarity(text1, text2, method",
        "<h3>'tfidf'):.3f}\")</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre># Different similarity metrics | print(f\"Cosine (BoW):     {cosine_similarity(text1, text2, method='bow'):.3f}\") | print(f\"Jaccard (words):  {jaccard_similarity(text1, text2, ngram_size=1):.3f}\")</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_bb6068602a4bd",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Similarity</b><br>Write the sim_matrix",
        "<h3>similarity_matrix(texts, method='cosine')</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre>] | print(\"\\nTexts:\") | for i, text in enumerate(texts):</pre></details>",
        "Similarity",
        "formula"
      ],
      "guid": "nlp_f3059a4e8943a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "similarity",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Stemming Lemmatization</b><br>What does <code>get_wordnet_pos()</code> do?",
        "<b>Purpose:</b> Convert Penn Treebank POS tags to WordNet POS tags.",
        "Stemming Lemmatization",
        "implementation"
      ],
      "guid": "nlp_eb64e55c9aa3a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "stemming_lemmatization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Stemming Lemmatization</b><br>What does <code>stem_words()</code> do?",
        "<b>Purpose:</b> Apply Porter stemming to words.",
        "Stemming Lemmatization",
        "implementation"
      ],
      "guid": "nlp_7f11bd7042ae9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "stemming_lemmatization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Stemming Lemmatization</b><br>What does <code>lemmatize_words()</code> do?",
        "<b>Purpose:</b> Lemmatize words with optional POS tags for better accuracy.",
        "Stemming Lemmatization",
        "implementation"
      ],
      "guid": "nlp_649f0654a37c0",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "stemming_lemmatization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Stemming Lemmatization</b><br>What does <code>compare_methods()</code> do?",
        "<b>Purpose:</b> Compare stemming vs lemmatization results.",
        "Stemming Lemmatization",
        "implementation"
      ],
      "guid": "nlp_8f8cecee331e2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "stemming_lemmatization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Stop Word Removal</b><br>What does <code>remove_stopwords()</code> do?",
        "<b>Purpose:</b> Remove stopwords, preserving order.",
        "Stop Word Removal",
        "implementation"
      ],
      "guid": "nlp_eb28be8608e36",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "stop_word_removal",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>What is tf-idf implementation?",
        "<b>Formula:</b> TF-IDF = TF * IDF",
        "Tfidf",
        "problem_understanding"
      ],
      "guid": "nlp_8efa2d4604db9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "problem_understanding"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>What does <code>compute_tfidf()</code> do?",
        "<b>Purpose:</b> Compute TF-IDF vectors for documents.",
        "Tfidf",
        "implementation"
      ],
      "guid": "nlp_91d8ea957beec",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>What does <code>cosine_similarity()</code> do?",
        "<b>Purpose:</b> Calculate cosine similarity between two TF-IDF vectors.",
        "Tfidf",
        "implementation"
      ],
      "guid": "nlp_cd1d7c260ed53",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>What does <code>find_similar_documents()</code> do?",
        "<b>Purpose:</b> Find most similar document to query using TF-IDF + cosine similarity.",
        "Tfidf",
        "implementation"
      ],
      "guid": "nlp_fa00b5c0a6074",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>Write the TF-IDF",
        "<h3>Term Frequency √ó Inverse Document Frequency</h3><br><p><i>TF-IDF: weights terms by frequency and rarity across documents</i></p><br><details><summary>Context</summary><pre>Compute TF-IDF vectors for documents. | - Emphasizes important words that appear frequently in a document | - But rarely across the entire collection</pre></details>",
        "Tfidf",
        "formula"
      ],
      "guid": "nlp_3c7957520d556",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>Write the Key Formula",
        "<h3>Used in IDF calculation: IDF = log(total_docs / doc_freq)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Tfidf",
        "formula"
      ],
      "guid": "nlp_46c0722bcb1bb",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>Write the Key Formula",
        "<h3>idf = math.log(num_docs / doc_freq[term])</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Tfidf",
        "formula"
      ],
      "guid": "nlp_7a456d172ceec",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>Write the similarity",
        "<h3>cosine_similarity(query_vector, doc_vector)</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre># Only compare with documents (exclude query vector) | for i, doc_vector in enumerate(tfidf_vectors[:-1]): | # Track the most similar document</pre></details>",
        "Tfidf",
        "formula"
      ],
      "guid": "nlp_ec0a788135eac",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>Write the Key Formula",
        "<h3>idf = math.log(len(docs) / df)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Tfidf",
        "formula"
      ],
      "guid": "nlp_2323d4f20fe38",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>Write the Key Formula",
        "<h3>idf = math.log(len(docs) / doc_freq[word])</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Tfidf",
        "formula"
      ],
      "guid": "nlp_0cfd723829daf",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>Write the print(f\"   '{word}': TF",
        "<h3>{tf:.3f}, IDF={idf:.3f}, TF-IDF={tfidf:.3f}\")</h3><br><p><i>TF-IDF: weights terms by frequency and rarity across documents</i></p><br><details><summary>Context</summary><pre>idf = math.log(len(docs) / doc_freq[word]) | tfidf = tf * idf | # Full computation</pre></details>",
        "Tfidf",
        "formula"
      ],
      "guid": "nlp_5fcb93ec4bd9b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>Write the sim",
        "<h3>cosine_similarity(query_vec, doc_vec)</h3><br><p><i>Cosine similarity: measures angle between vectors (0=orthogonal, 1=identical)</i></p><br><details><summary>Context</summary><pre>for i, doc in enumerate(docs): | doc_vec = tfidf_vectors[i] | print(f\"   Similarity with doc {i}: {sim:.3f}\")</pre></details>",
        "Tfidf",
        "formula"
      ],
      "guid": "nlp_fe82e052c56f8",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>What's the Time Complexity?",
        "<b>O(d√óv)</b><br><i>See Big O notation reference</i>",
        "Tfidf",
        "complexity"
      ],
      "guid": "nlp_c50c8b9631175",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "complexity"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>What's the Space Complexity?",
        "<b>O(d√óv)</b><br><i>See Big O notation reference</i>",
        "Tfidf",
        "complexity"
      ],
      "guid": "nlp_fe9daeb0fd43b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "complexity"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tfidf</b><br>üí° Why is this important in interviews?",
        "<p><strong>DEMO: Show step-by-step execution</strong></p>",
        "Tfidf",
        "interview_insights"
      ],
      "guid": "nlp_a2e75e84f3ff1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tfidf",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>What does <code>extract_features()</code> do?",
        "<b>Purpose:</b> Extract features from texts for classification.",
        "Text Classification",
        "implementation"
      ],
      "guid": "nlp_5cef7374ab0d0",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>What does <code>train_logistic_regression()</code> do?",
        "<b>Purpose:</b> Train logistic regression classifier from scratch.",
        "Text Classification",
        "implementation"
      ],
      "guid": "nlp_a817a04dc7666",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>What does <code>predict_logistic()</code> do?",
        "<b>Purpose:</b> Make predictions with trained logistic regression model.",
        "Text Classification",
        "implementation"
      ],
      "guid": "nlp_d3a53ea3e73c2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>What does <code>evaluate_classifier()</code> do?",
        "<b>Purpose:</b> Calculate key evaluation metrics.",
        "Text Classification",
        "implementation"
      ],
      "guid": "nlp_ccb7bbfec3557",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>Write the Key Formula",
        "<h3>idf = math.log(len(texts) / doc_freq[word])</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Text Classification",
        "formula"
      ],
      "guid": "nlp_c8a9394a082a5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>Write the Key Formula",
        "<h3>Linear part: Xw + b</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Text Classification",
        "formula"
      ],
      "guid": "nlp_2f6f862de95c1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>Write the Key Formula",
        "<h3>Sigmoid: maps to [0,1]</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Text Classification",
        "formula"
      ],
      "guid": "nlp_ece487aa74462",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>Write the Key Formula",
        "<h3>logits = X_with_bias @ model['weights']</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Text Classification",
        "formula"
      ],
      "guid": "nlp_078be6fe32897",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>Write the Key Formula",
        "<h3>probabilities = 1 / (1 + np.exp(-logits))</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Text Classification",
        "formula"
      ],
      "guid": "nlp_7967224f941ff",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>Write the Key Formula",
        "<h3>model = train_logistic_regression(X_train, train_labels)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Text Classification",
        "formula"
      ],
      "guid": "nlp_2e4c559348605",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>Write the Key Formula",
        "<h3>predictions = predict_logistic(X_test, model)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Text Classification",
        "formula"
      ],
      "guid": "nlp_16d21c1280e1d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Text Classification</b><br>Write the Key Formula",
        "<h3>train_predictions = predict_logistic(X_train, model)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Text Classification",
        "formula"
      ],
      "guid": "nlp_74de93297f5c1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "text_classification",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>What does <code>tokenize()</code> do?",
        "<b>Purpose:</b> Tokenize text into words, preserving contractions and handling punctuation.",
        "Tokenization",
        "implementation"
      ],
      "guid": "nlp_8ce834267a330",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>What does <code>tokenize_simple()</code> do?",
        "<b>Purpose:</b> Alternative approach: Replace-then-split method.",
        "Tokenization",
        "implementation"
      ],
      "guid": "nlp_c76862ebf9f40",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>What does <code>advanced_tokenize()</code> do?",
        "<b>Purpose:</b> Advanced tokenization with additional features.",
        "Tokenization",
        "implementation"
      ],
      "guid": "nlp_67aa3d17b91b7",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>What does <code>handle_contractions_explicitly()</code> do?",
        "<b>Purpose:</b> Explicit contraction handling - shows deep understanding.",
        "Tokenization",
        "implementation"
      ],
      "guid": "nlp_e9a7745399b69",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>What does <code>test_tokenization()</code> do?",
        "<b>Purpose:</b> Comprehensive test cases that cover edge cases interviewers ask about.",
        "Tokenization",
        "implementation"
      ],
      "guid": "nlp_3a2221c8331e9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>What's the Time Complexity?",
        "<b>O(n)</b><br><i>Linear time - grows proportionally with input size</i>",
        "Tokenization",
        "complexity"
      ],
      "guid": "nlp_51da2c193b99c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "complexity"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>What's the Space Complexity?",
        "<b>O(n)</b><br><i>Linear time - grows proportionally with input size</i>",
        "Tokenization",
        "complexity"
      ],
      "guid": "nlp_19008083fa32e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "complexity"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>üí° Why is this important in interviews?",
        "<p><strong>DEMO: Show your thinking process</strong></p>",
        "Tokenization",
        "interview_insights"
      ],
      "guid": "nlp_7317ff70b6254",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>Key concept:",
        "<p>Alternative approach: Replace-then-split method</p>",
        "Tokenization",
        "concepts"
      ],
      "guid": "nlp_ff156324498a5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "concepts"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>Key concept:",
        "<p>Sometimes interviewers want to see multiple approaches</p>",
        "Tokenization",
        "concepts"
      ],
      "guid": "nlp_2bb91f4141a8a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "concepts"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>Key concept:",
        "<p>This is simpler</p>",
        "Tokenization",
        "concepts"
      ],
      "guid": "nlp_2ce37fa4b0c0a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "concepts"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization</b><br>Key concept:",
        "<p>less robust than regex.</p>",
        "Tokenization",
        "concepts"
      ],
      "guid": "nlp_714342ba60f79",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization",
        "concepts"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization Advanced</b><br>What does <code>get_word_frequencies()</code> do?",
        "<b>Purpose:</b> Get word frequencies with end-of-word marker.",
        "Tokenization Advanced",
        "implementation"
      ],
      "guid": "nlp_2dbf868c12f57",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization_advanced",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization Advanced</b><br>What does <code>get_pairs()</code> do?",
        "<b>Purpose:</b> Get all adjacent character pairs with their frequencies.",
        "Tokenization Advanced",
        "implementation"
      ],
      "guid": "nlp_86b9e7848793e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization_advanced",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization Advanced</b><br>What does <code>merge_vocab()</code> do?",
        "<b>Purpose:</b> Merge most frequent pair in vocabulary.",
        "Tokenization Advanced",
        "implementation"
      ],
      "guid": "nlp_dcd70e4a167e2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization_advanced",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization Advanced</b><br>What does <code>build_bpe_vocab()</code> do?",
        "<b>Purpose:</b> Build BPE vocabulary through iterative merging.",
        "Tokenization Advanced",
        "implementation"
      ],
      "guid": "nlp_5f7708383611f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization_advanced",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization Advanced</b><br>What does <code>bpe_encode()</code> do?",
        "<b>Purpose:</b> Encode text using BPE vocabulary.",
        "Tokenization Advanced",
        "implementation"
      ],
      "guid": "nlp_473b14ea619b9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization_advanced",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization Advanced</b><br>What does <code>bpe_decode()</code> do?",
        "<b>Purpose:</b> Decode BPE tokens back to text.",
        "Tokenization Advanced",
        "implementation"
      ],
      "guid": "nlp_8adad29ee04c4",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization_advanced",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Tokenization Advanced</b><br>What does <code>simulate_wordpiece()</code> do?",
        "<b>Purpose:</b> Simulate WordPiece tokenization (greedy longest-match).",
        "Tokenization Advanced",
        "implementation"
      ],
      "guid": "nlp_a1fb871cecd24",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "tokenization_advanced",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>perform_lsa()</code> do?",
        "<b>Purpose:</b> Perform Latent Semantic Analysis.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_709ce685ca18b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>perform_lda()</code> do?",
        "<b>Purpose:</b> Perform Latent Dirichlet Allocation.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_a93779bd4d26e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>extract_topics()</code> do?",
        "<b>Purpose:</b> Extract topics from model.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_bc1c8d952c013",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>get_document_topics()</code> do?",
        "<b>Purpose:</b> Get topic distribution for a document.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_1d572861e4eba",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>calculate_coherence_score()</code> do?",
        "<b>Purpose:</b> Calculate topic coherence score (simplified version).",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_95350913ea04f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>compare_topic_models()</code> do?",
        "<b>Purpose:</b> Compare different topic modeling approaches.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_0336590d3424b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>__init__()</code> do?",
        "",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_b5c4d1e21f0b6",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>fit()</code> do?",
        "<b>Purpose:</b> Fit LSA model to documents.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_784496d4dcf05",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>get_topics()</code> do?",
        "<b>Purpose:</b> Extract top words for each topic.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_6e0552f35d56a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>transform()</code> do?",
        "<b>Purpose:</b> Transform documents to topic space.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_53530b9292064",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>__init__()</code> do?",
        "",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_b5c4d1e21f0b6",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>fit()</code> do?",
        "<b>Purpose:</b> Fit LDA model to documents.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_f0c9d8c99c710",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>_fit_sklearn()</code> do?",
        "<b>Purpose:</b> Fit using sklearn's LDA.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_e8f24371f19e1",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>_fit_from_scratch()</code> do?",
        "<b>Purpose:</b> Simplified LDA using Gibbs sampling.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_0ee50e8f6a459",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>get_topics()</code> do?",
        "<b>Purpose:</b> Extract top words for each topic.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_6e0552f35d56a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>What does <code>transform()</code> do?",
        "<b>Purpose:</b> Transform documents to topic space.",
        "Topicmodeling",
        "implementation"
      ],
      "guid": "nlp_53530b9292064",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>üîç Why is this important in interviews?",
        "<p><strong>Calculate topic coherence score (simplified version).</strong></p>",
        "Topicmodeling",
        "interview_insights"
      ],
      "guid": "nlp_8503b0eca314b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Topicmodeling</b><br>Key concept:",
        "<p>Compare different topic modeling approaches.</p>",
        "Topicmodeling",
        "concepts"
      ],
      "guid": "nlp_5a30e433cb5ae",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "topicmodeling",
        "concepts"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>load_pretrained_bert()</code> do?",
        "<b>Purpose:</b> Load pre-trained BERT model and tokenizer.",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_d6dc9df370217",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>fine_tune_bert()</code> do?",
        "<b>Purpose:</b> Fine-tune BERT for sentiment analysis.",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_80dd8b3cf8e5d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>predict_with_bert()</code> do?",
        "<b>Purpose:</b> Make predictions with BERT model.",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_9cb666d2a66b2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>compare_transformer_models()</code> do?",
        "<b>Purpose:</b> Compare different transformer models.",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_fa2ac32c6626e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>few_shot_sentiment()</code> do?",
        "<b>Purpose:</b> Few-shot learning with prompts (for GPT-style models).",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_7331dbbd0ccfe",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>visualize_attention()</code> do?",
        "<b>Purpose:</b> Simple text-based attention visualization.",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_f863c29a25d97",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>create_imdb_sample_data()</code> do?",
        "<b>Purpose:</b> Create sample IMDB-style movie review data.",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_8457178b90e6a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>__init__()</code> do?",
        "",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_e12e199237545",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>__len__()</code> do?",
        "",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_e79fa076910b5",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>__getitem__()</code> do?",
        "",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_c27c05dcb8017",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>__init__()</code> do?",
        "",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_e12e199237545",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>What does <code>forward()</code> do?",
        "",
        "Transformers",
        "implementation"
      ],
      "guid": "nlp_98dd5b04e3d74",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>Write the Key Formula",
        "<h3>logits = self.classifier(pooled_output)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Transformers",
        "formula"
      ],
      "guid": "nlp_7c8caed00f55a",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>Write the Key Formula",
        "<h3>logits, _, _ = model(input_ids, attention_mask)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Transformers",
        "formula"
      ],
      "guid": "nlp_71bb9a0184ae3",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>Write the Key Formula",
        "<h3>logits = outputs.logits</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Transformers",
        "formula"
      ],
      "guid": "nlp_00024fa17c76b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>Write the Key Formula",
        "<h3>loss = criterion(logits, labels)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Transformers",
        "formula"
      ],
      "guid": "nlp_3a6a5b3a0c785",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>Write the Key Formula",
        "<h3>_, predicted = torch.max(logits, 1)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Transformers",
        "formula"
      ],
      "guid": "nlp_20ab487ce49dd",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>Write the Key Formula",
        "<h3>logits, attentions, cls_embedding = model(input_ids, attention_mask)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Transformers",
        "formula"
      ],
      "guid": "nlp_bcb3e9c9d485b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>Write the Key Formula",
        "<h3>logits = outputs.logits</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Transformers",
        "formula"
      ],
      "guid": "nlp_00024fa17c76b",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>Write the Key Formula",
        "<h3>probs = torch.softmax(logits, dim=-1)</h3><br><p><i>Mathematical relationship used in this algorithm</i></p>",
        "Transformers",
        "formula"
      ],
      "guid": "nlp_436826860ab0c",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "formula"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>üîç Why is this important in interviews?",
        "<p><strong>Transformers enable parallel computation unlike RNNs</strong></p>",
        "Transformers",
        "interview_insights"
      ],
      "guid": "nlp_d392630170e75",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Transformers</b><br>üîç Why is this important in interviews?",
        "<p><strong>Multi-head attention captures different relationship types</strong></p>",
        "Transformers",
        "interview_insights"
      ],
      "guid": "nlp_e35ff88ba47a6",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "transformers",
        "interview_insights"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>expand_contractions()</code> do?",
        "<b>Purpose:</b> Expand contractions in text.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_72760b401d666",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>expand_abbreviations()</code> do?",
        "<b>Purpose:</b> Expand common abbreviations.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_5204b9283a718",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>clean_html()</code> do?",
        "<b>Purpose:</b> Remove HTML tags and decode entities.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_d0b0d111e6b93",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>normalize_unicode()</code> do?",
        "<b>Purpose:</b> Normalize Unicode characters.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_26481980e8e05",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>normalize_whitespace()</code> do?",
        "<b>Purpose:</b> Normalize whitespace in text.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_453333cf5eb99",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>normalize_punctuation()</code> do?",
        "<b>Purpose:</b> Normalize punctuation in text.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_0754b0802b490",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>handle_urls()</code> do?",
        "<b>Purpose:</b> Handle URLs in text.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_a117629369243",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>handle_emails()</code> do?",
        "<b>Purpose:</b> Handle email addresses in text.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_92b87e3b13666",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>handle_phone_numbers()</code> do?",
        "<b>Purpose:</b> Handle phone numbers in text.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_a11bc5403c913",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>handle_numbers()</code> do?",
        "<b>Purpose:</b> Handle numbers in text.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_bf69fa95481bc",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>handle_social_media()</code> do?",
        "<b>Purpose:</b> Handle social media specific elements.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_d26b1a6bcaa5f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>remove_emojis()</code> do?",
        "<b>Purpose:</b> Remove emoji characters from text.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_e0f8b01955f08",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>normalize_text()</code> do?",
        "<b>Purpose:</b> Main text normalization function with configurable options.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_281d043d1fc01",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>batch_normalize()</code> do?",
        "<b>Purpose:</b> Normalize multiple texts with the same options.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_17faccd07a2af",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>create_custom_normalizer()</code> do?",
        "<b>Purpose:</b> Create a custom normalizer that preserves specific entities.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_96d21bc867e9e",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>get_normalization_stats()</code> do?",
        "<b>Purpose:</b> Get statistics about the normalization process.",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_7e2ab7adf72e2",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>custom_normalize()</code> do?",
        "",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_23706c275512d",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>replace_url()</code> do?",
        "",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_c30a9d291630f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>replace_url()</code> do?",
        "",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_c30a9d291630f",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "<b>Utilities</b><br>What does <code>replace_email()</code> do?",
        "",
        "Utilities",
        "implementation"
      ],
      "guid": "nlp_7c866afd9e6d9",
      "note_model_uuid": "nlp-model-rules-optimized",
      "tags": [
        "utilities",
        "implementation"
      ]
    }
  ]
}