{
  "__type__": "Deck",
  "children": [],
  "crowdanki_uuid": "ml-model-evaluation--metrics-2024",
  "deck_config_uuid": "ml-interview-config",
  "deck_configurations": [
    {
      "__type__": "DeckConfig",
      "autoplay": true,
      "crowdanki_uuid": "ml-interview-config",
      "dyn": false,
      "name": "Model Evaluation & Metrics",
      "new": {
        "bury": true,
        "delays": [
          1,
          10
        ],
        "initialFactor": 2500,
        "ints": [
          1,
          4,
          7
        ],
        "order": 1,
        "perDay": 20,
        "separate": true
      },
      "rev": {
        "bury": true,
        "ease4": 1.3,
        "fuzz": 0.05,
        "ivlFct": 1.0,
        "maxIvl": 36500,
        "minSpace": 1,
        "perDay": 150
      }
    }
  ],
  "desc": "Performance measurement and model validation techniques",
  "dyn": 0,
  "extendNew": 10,
  "extendRev": 50,
  "media_files": [],
  "name": "Model Evaluation & Metrics",
  "note_models": [
    {
      "__type__": "NoteModel",
      "crowdanki_uuid": "ml-interview-model",
      "css": "\n.card {\n    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n    font-size: 16px;\n    line-height: 1.5;\n    color: #333;\n    background-color: #fafafa;\n    padding: 20px;\n    max-width: 600px;\n    margin: 0 auto;\n}\n\n.front { \n    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n    color: white;\n    padding: 25px;\n    border-radius: 10px;\n}\n\n.back { \n    background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n    color: white;\n    padding: 25px;\n    border-radius: 10px;\n}\n\nb { color: #ffeb3b; font-weight: 600; }\n.formula { \n    font-family: 'Courier New', monospace; \n    background: rgba(255,255,255,0.2); \n    padding: 3px 6px; \n    border-radius: 4px;\n    font-size: 14px;\n}\n.example { font-style: italic; opacity: 0.9; }\n                    ",
      "flds": [
        {
          "__type__": "NoteModelField",
          "name": "Front",
          "ord": 0,
          "sticky": false
        },
        {
          "__type__": "NoteModelField",
          "name": "Back",
          "ord": 1,
          "sticky": false
        },
        {
          "__type__": "NoteModelField",
          "name": "Topic",
          "ord": 2,
          "sticky": false
        },
        {
          "__type__": "NoteModelField",
          "name": "Type",
          "ord": 3,
          "sticky": false
        }
      ],
      "name": "ML Interview Card",
      "req": [
        [
          0,
          "any",
          [
            0
          ]
        ]
      ],
      "sortf": 0,
      "tags": [],
      "tmpls": [
        {
          "__type__": "CardTemplate",
          "afmt": "<div class=\"card back\">{{Front}}<hr>{{Back}}<br><br><small><i>{{Topic}} • {{Type}}</i></small></div>",
          "bafmt": "",
          "bqfmt": "",
          "did": null,
          "name": "Card",
          "ord": 0,
          "qfmt": "<div class=\"card front\">{{Front}}</div>"
        }
      ],
      "type": 0,
      "vers": []
    }
  ],
  "notes": [
    {
      "__type__": "Note",
      "fields": [
        "Define precision, recall, and F1-score. When would you prioritize each?",
        "<b>Precision:</b> TP/(TP+FP) - fraction of positive predictions that are correct<br>\n<b>Recall:</b> TP/(TP+FN) - fraction of actual positives identified<br>\n<b>F1-score:</b> 2×(P×R)/(P+R) - harmonic mean of precision and recall<br>\n<b>Prioritize precision:</b> When false positives are costly (spam detection)",
        "Model Evaluation & Metrics",
        "interview_concept"
      ],
      "guid": "ml_897365e5",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "model_evaluation_&_metrics",
        "interview_concept",
        "ml_interview"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "What is the ROC curve and what does AUC represent?",
        "<b>ROC:</b> True Positive Rate vs False Positive Rate at different thresholds<br>\n<b>AUC:</b> Area Under Curve - probability model ranks random positive > random negative<br>\n<b>AUC = 0.5:</b> Random classifier (no discrimination)<br>\n<b>AUC = 1.0:</b> Perfect classifier",
        "Model Evaluation & Metrics",
        "interview_concept"
      ],
      "guid": "ml_74f8edae",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "model_evaluation_&_metrics",
        "interview_concept",
        "ml_interview"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "What is cross-validation and why is it important?",
        "<b>Purpose:</b> Assess model generalization by training/testing on different data splits<br>\n<b>K-fold:</b> Split data into k parts, train on k-1, test on 1, repeat k times<br>\n<b>Benefits:</b> Reduces overfitting, better performance estimate, model selection<br>\n<b>Stratified:</b> Maintains class distribution in each fold",
        "Model Evaluation & Metrics",
        "interview_concept"
      ],
      "guid": "ml_74b53f32",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "model_evaluation_&_metrics",
        "interview_concept",
        "ml_interview"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "What are MAE, MSE, and RMSE? When would you use each?",
        "<b>MAE:</b> Mean Absolute Error - average absolute differences<br>\n<b>MSE:</b> Mean Squared Error - average squared differences<br>\n<b>RMSE:</b> Root Mean Squared Error - √MSE, same units as target<br>\n<b>Use MAE:</b> When outliers shouldn't dominate; <b>MSE/RMSE:</b> When large errors are especially bad",
        "Model Evaluation & Metrics",
        "interview_concept"
      ],
      "guid": "ml_1e07375e",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "model_evaluation_&_metrics",
        "interview_concept",
        "ml_interview"
      ]
    }
  ]
}