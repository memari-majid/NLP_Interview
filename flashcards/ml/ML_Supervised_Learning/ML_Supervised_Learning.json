{
  "__type__": "Deck",
  "children": [],
  "crowdanki_uuid": "ml-supervised-learning-2024",
  "deck_config_uuid": "ml-interview-config",
  "deck_configurations": [
    {
      "__type__": "DeckConfig",
      "autoplay": true,
      "crowdanki_uuid": "ml-interview-config",
      "dyn": false,
      "name": "Supervised Learning",
      "new": {
        "bury": true,
        "delays": [
          1,
          10
        ],
        "initialFactor": 2500,
        "ints": [
          1,
          4,
          7
        ],
        "order": 1,
        "perDay": 20,
        "separate": true
      },
      "rev": {
        "bury": true,
        "ease4": 1.3,
        "fuzz": 0.05,
        "ivlFct": 1.0,
        "maxIvl": 36500,
        "minSpace": 1,
        "perDay": 150
      }
    }
  ],
  "desc": "Classification and regression algorithms and techniques",
  "dyn": 0,
  "extendNew": 10,
  "extendRev": 50,
  "media_files": [],
  "name": "Supervised Learning",
  "note_models": [
    {
      "__type__": "NoteModel",
      "crowdanki_uuid": "ml-interview-model",
      "css": "\n.card {\n    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n    font-size: 16px;\n    line-height: 1.5;\n    color: #333;\n    background-color: #fafafa;\n    padding: 20px;\n    max-width: 600px;\n    margin: 0 auto;\n}\n\n.front { \n    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n    color: white;\n    padding: 25px;\n    border-radius: 10px;\n}\n\n.back { \n    background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n    color: white;\n    padding: 25px;\n    border-radius: 10px;\n}\n\nb { color: #ffeb3b; font-weight: 600; }\n.formula { \n    font-family: 'Courier New', monospace; \n    background: rgba(255,255,255,0.2); \n    padding: 3px 6px; \n    border-radius: 4px;\n    font-size: 14px;\n}\n.example { font-style: italic; opacity: 0.9; }\n                    ",
      "flds": [
        {
          "__type__": "NoteModelField",
          "name": "Front",
          "ord": 0,
          "sticky": false
        },
        {
          "__type__": "NoteModelField",
          "name": "Back",
          "ord": 1,
          "sticky": false
        },
        {
          "__type__": "NoteModelField",
          "name": "Topic",
          "ord": 2,
          "sticky": false
        },
        {
          "__type__": "NoteModelField",
          "name": "Type",
          "ord": 3,
          "sticky": false
        }
      ],
      "name": "ML Interview Card",
      "req": [
        [
          0,
          "any",
          [
            0
          ]
        ]
      ],
      "sortf": 0,
      "tags": [],
      "tmpls": [
        {
          "__type__": "CardTemplate",
          "afmt": "<div class=\"card back\">{{Front}}<hr>{{Back}}<br><br><small><i>{{Topic}} • {{Type}}</i></small></div>",
          "bafmt": "",
          "bqfmt": "",
          "did": null,
          "name": "Card",
          "ord": 0,
          "qfmt": "<div class=\"card front\">{{Front}}</div>"
        }
      ],
      "type": 0,
      "vers": []
    }
  ],
  "notes": [
    {
      "__type__": "Note",
      "fields": [
        "How does logistic regression work and what are its key assumptions?",
        "<b>Method:</b> Uses sigmoid function to map any real value to (0,1)<br>\n<b>Formula:</b> p = 1/(1 + e^(-z)), where z = β₀ + β₁x₁ + β₂x₂ + ...<br>\n<b>Assumptions:</b> Linear relationship between features and log-odds<br>\n<b>Use case:</b> Binary/multi-class classification with probabilistic output",
        "Supervised Learning",
        "interview_concept"
      ],
      "guid": "ml_3a2e7a63",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "supervised_learning",
        "interview_concept",
        "ml_interview"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "What is the difference between bagging and boosting?",
        "<b>Bagging:</b> Train models in parallel on different data subsets (Bootstrap AGGregating)<br>\n<b>Boosting:</b> Train models sequentially, each correcting previous errors<br>\n<b>Bagging goal:</b> Reduce variance (Random Forest)<br>\n<b>Boosting goal:</b> Reduce bias (AdaBoost, XGBoost)",
        "Supervised Learning",
        "interview_concept"
      ],
      "guid": "ml_59bdcd6f",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "supervised_learning",
        "interview_concept",
        "ml_interview"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "How do Random Forests work and why are they effective?",
        "<b>Method:</b> Ensemble of decision trees with random feature/sample selection<br>\n<b>Training:</b> Bootstrap sampling + random feature subset at each split<br>\n<b>Prediction:</b> Average (regression) or majority vote (classification)<br>\n<b>Benefits:</b> Reduces overfitting, handles missing values, feature importance",
        "Supervised Learning",
        "interview_concept"
      ],
      "guid": "ml_6d9c4c8a",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "supervised_learning",
        "interview_concept",
        "ml_interview"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "Explain Support Vector Machines (SVM) and the kernel trick.",
        "<b>Goal:</b> Find optimal hyperplane that maximizes margin between classes<br>\n<b>Support vectors:</b> Data points closest to decision boundary<br>\n<b>Kernel trick:</b> Map data to higher dimensions without explicit computation<br>\n<b>Kernels:</b> Linear, polynomial, RBF (Gaussian), sigmoid",
        "Supervised Learning",
        "interview_concept"
      ],
      "guid": "ml_634d4ba4",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "supervised_learning",
        "interview_concept",
        "ml_interview"
      ]
    },
    {
      "__type__": "Note",
      "fields": [
        "What is regularization and how do Ridge, Lasso, and Elastic Net differ?",
        "<b>Purpose:</b> Prevent overfitting by penalizing complex models<br>\n<b>Ridge (L2):</b> Penalty = λΣβᵢ² → shrinks coefficients toward zero<br>\n<b>Lasso (L1):</b> Penalty = λΣ|βᵢ| → sparse solutions, feature selection<br>\n<b>Elastic Net:</b> Combines L1 + L2 penalties for best of both",
        "Supervised Learning",
        "interview_concept"
      ],
      "guid": "ml_e40fca65",
      "note_model_uuid": "ml-interview-model",
      "tags": [
        "supervised_learning",
        "interview_concept",
        "ml_interview"
      ]
    }
  ]
}